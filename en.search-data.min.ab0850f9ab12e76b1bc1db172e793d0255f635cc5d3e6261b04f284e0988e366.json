[{"id":0,"href":"/docs/about/","title":"About","section":"Docs","content":"About me #  "},{"id":1,"href":"/docs/contact/","title":"Contact","section":"Docs","content":"Contact #  You can contact me through:\n Email: angeletti.gabriele@gmail.com LinkedIn Twitter  "},{"id":2,"href":"/docs/topics/mental-models/bias/","title":"Biases","section":"Mental models","content":"Biases #  foo.\n"},{"id":3,"href":"/docs/topics/software-engineering/design/","title":"Design","section":"Software Engineering","content":"Design #  foo.\n"},{"id":4,"href":"/docs/topics/mental-models/","title":"Mental models","section":"Topics","content":"Mental models #  List of mental models I\u0026rsquo;m interested in.\n"},{"id":5,"href":"/docs/topics/software-engineering/","title":"Software Engineering","section":"Topics","content":"Software engineering #  foo\n"},{"id":6,"href":"/docs/topics/mental-models/bias/confirmation-bias/","title":"Confirmation Bias","section":"Biases","content":"Confirmation bias #  Introduction #  Confirmation bias is a mental model in which we cherry-pick evidence that confirms our beliefs while rejecting or ignoring anything that goes against them. This tendence is stronger in case of ideologically or emotionally charged arguments.\nWhen we want a certain idea to be true, and we end up thinking and acting as if it was true, that is confirmation bias in action. Our eyes and brains filter out any information that would disprove what we have already decided to be true beyond doubt. On the contrary, we thoroughly embrace any bit of data that confirms our views, no matter how insignificant.\nWe basically stop perceiving the evidence objectively and start cherry-picking all those bits that strenghten our prior theories.\n \u0026ldquo;What the human being is best at doing is interpreting all new information so that their prior conclusions remain intact.\u0026quot;\n\u0026ndash; Warren Buffett\n Examples #   When it comes to social and political issues, people are entrenched in their existing beliefs and unwilling to change them, no matter how convincing the conflicting evidence can be. Even worse, after considering and rejecting the evidence, people tend to become even more confident in the superiority of their positions. Socially anxious people have a marked tendency to interpret others' behaviours as confirming their beliefs that they\u0026rsquo;re being judged, that people don\u0026rsquo;t like them and so on. Any signal that suggests something negative is given paramount important, while positive signals are disregarded altogether. A consequence of confirmation bias is making self-fulfilling prophecies happen. For example, if you think you will suck at tomorrow\u0026rsquo;s work presentation, you might end up having a sleepless night - which in turns increases the chance of you actually sucking at the presenation.  History #  Confirmation bias was first identified by the ancient Greeks. In The History of the Peloponnesian War, Thucydides (c. 460 BC - c. 395 BC) said:\n \u0026ldquo;For it is a habit of humanity to entrust to careless hope what they long for, and to use sovereign reason to thrust aside what they do not fancy.\u0026quot;\n The Italian poet Dante Alighieri (1265-1321) noted in the Divine Comedy:\n \u0026ldquo;Opinion\u0026ndash;hasty\u0026ndash;often can incline to the wrong side, and then affection for one\u0026rsquo;s own opinion binds, confines the mind.\u0026quot;\n In his Muqaddimah (1377), the Arab historian Ibn Khaldun says:\n \u0026ldquo;Untruth naturally afflicts historical information. There are various reasons that make this unavoidable. One of them is partisanship for opinions and schools. [\u0026hellip;] If the soul is infected with partisanship for a particular opinion or sect, it accepts without a moment\u0026rsquo;s hesitation the information that is agreeable to it. Prejudice and partisanship obscure the critical faculty and preclude critical investigation. The result is that falsehoods are accepted and transmitted.\u0026quot;\n In his Novum Organum, English philosopher and scientist Francis Bacon (1561-1626) says:\n \u0026ldquo;The human understanding when it has once adopted an opinion \u0026hellip; draws all things else to support and agree with it. And though there be a greater number and weight of instances to be found on the other side, yet these it either neglects or despises, or else by some distinction sets aside or rejects.\u0026quot;\n In the second volume of The World as Will and Representation, German philosopher Arthur Schopenhauer says:\n \u0026ldquo;An adopted hypothesis gives us lynx-eyes for everything that confirms it and makes us blind to everything that contradicts it.\u0026quot;\n In his essay What is Art? (1897) Leo Tolstoy wrote:\n \u0026ldquo;I know that most men\u0026ndash;not only those considered clever, but even those who are very clever, and capable of understanding most difficult scientific, mathematical, or philosophic problems\u0026ndash;can very seldom discern even the simplest and most obvious truth if it be such as to oblige them to admit the falsity of conclusions they have formed, perhaps with much difficulty\u0026ndash;conclusions of which they are proud, which they have taught to others, and on which they have built their lives.\u0026quot;\n He also says in his essay The Kingdom of God Is Within You (1894):\n \u0026ldquo;The most difficult subjects can be explained to the most slow-witted man if he has not formed any idea of them already; but the simplest thing cannot be made clear to the most intelligent man if he is firmly persuaded that he knows already, without a shadow of doubt, what is laid before him.\u0026quot;\n Confirmation bias and the brain #  From an evolutionary perspective, having this bias makes sense, because it makes us save energy. Carefully and objectively analysing data requires a ton of effort. It is the reason why our brains like shortcuts. Also, in ancient times we didn\u0026rsquo;t really have the luxury of sitting down, carefully weighting all the evidence, make pros and cons lists, and so on. In those times, the vast majority of decisions were about survival. Fight or flight and all that. The modern world brought with it incredible complexity, which our brains are definitely not equipped to handle. Today, we have to make multiple complex decisions every single day. No wonder we\u0026rsquo;re always looking for shortcuts, our brains would explode otherwise.\nAlso, your brain spent countless hours creating and refining its mental model of how the world works. Evidence that challeges this model is hard to accept, because it would invalidate all the effort spent in building the model and because it\u0026rsquo;s a threat to our sense of identity that\u0026rsquo;s been created around this model of the world.\nConfirmation bias, conspiracy theories and social media #  Confirmation bias is behind a lot of conspiracy theories, where people only look at those bits of evidence supporting their theories while rejecting everything else.\nIt is also used by social media companies like Facebook in their news feed. The algorithm behind the news feed shows you content you are likely to agree with, thereby feeding your already existing confirmation biases.\nWhat to do about it #  Confirmation bias prevents us from realizing we were wrong, thus blocking the progress of our knowledge and of our journey towards becoming better decision makers. What we can do about it:\n Acknowledge that the world is an incredibly complicated thing to deal with, and that no matter how confident you are in your opinions, new evidence that throws your hypotheses in the gargabe could arrive any moment. Use the scientific method. Instead of thinking \u0026ldquo;How can I prove this is true?\u0026rdquo;, think \u0026ldquo;How can I prove this is bullshit?\u0026rdquo;. If despite your effort you cannot find convincing evidence your idea is bullshit, that is a pretty good argument in favor of it.  "},{"id":7,"href":"/docs/topics/software-engineering/design/api/","title":"API","section":"Design","content":"API design #  NENO (non-exhaustive, non-ordered) list of questions to keep in mind and ask yourself when designing an API, or any software for that matter.\n Imagine a developer with zero knowledge of your API starts using it. How long will they take to be proficient with it? How much new knowledge do they need to acquire? How much prior knowledge can they reuse? If I imagine myself using this API tomorrow, would that be a pleasurable experience? Can someone understand what each function/endpoint does just by looking at the signature? Do the default values make sense? Is the naming and the order/type of the parameters consistent? Is it well documented? Can I get all the information I need without having to look at the code? Are things obvious? And if they\u0026rsquo;re not, is there a good reason for that? Does using the API require to write a lot of duplicated code? Can that be avoided? Is it easy for the users to do the right thing? Is it hard to do the wrong thing?  "},{"id":8,"href":"/docs/topics/software-engineering/design/code/","title":"Code","section":"Design","content":"Writing code #  NENO (non-exhaustive, non-ordered) list of things to think about when writing code:\nNaming #  Naming stuff is one of the most important aspects in software engineering. Everything must have a name - variables, functions, classes, modules, packages. Names should be as simple as possible, but not simpler than that. They say what the thing is, or does, they are consistent across the code base and they make reading code easier.\nVariables #  Variable names should be explicit, and give enough information so that the reader knows what\u0026rsquo;s going on. A good name is a name that doesn\u0026rsquo;t make us ask questions. When you read this - int duration = 1800; - you ask questions. Duration of what? What\u0026rsquo;s the unit? When you read this - int half_hour_in_seconds = 1800; - you know that this variable represents half an hour, and the unit is seconds. No need to ask questions. Also, if part of the name doesn\u0026rsquo;t add additional information, remove it. In int half_hour_in_seconds_integer = 1800;, the _integer suffix is not needed, because the type of the variable already says it\u0026rsquo;s an integer.\nFunctions #  Ideally, you should be able to understand what a function does by reading its signature. The signature is the name, the parameters, and the return type. A good side-effect of this principle is that it forces you (or motivates you at least), to write good code.\nFirst of all, it will be easier to respect the Single Responsibility Principle. According to this principle, each function must do one thing and one thing only. And it\u0026rsquo;s very hard to find a good name for a function that does many things. Imagine a function that downloads a web page from the internet, counts the occurrences of each word and uploads the results to a database. How would you call this function? FetchDataComputeOccurrencesUploadToDb? That\u0026rsquo;s a ridiculous name. This is also a good test for the quality of the code you write. If it\u0026rsquo;s hard to come up with a name for a function, that\u0026rsquo;s a code smell. In the example we just made, it\u0026rsquo;s clear that the function does too many things and need to be split in three. Of course, at some higher level in the hierarchy you will have wrapper functions that do more than one thing. But in those cases, the function should only call the lower-level functions and do nothing else. And those lower-level functions must be logically related. If they are, then it will be easy to name the high-level one.\nAlso, functions with good names improve re-usability of your code. When a function does one thing there\u0026rsquo;s a higher chance that the same use case will appear somewhere else and you will be able to re-use the code. In general, when a function is named well it will be easier to re-use it. A good name has to say what the function does. When I say what the function does I mean its input-output behaviour. The name should not mention what the function does internally, because that can change at any time. But the name should say anything that a user of the function should be aware of. Consider the following function:\ndef write(data: Union[Dict, List], options: Dict[str, Any]) -\u0026gt; None: if \u0026#34;mode\u0026#34; not in options: options[\u0026#34;mode\u0026#34;] = \u0026#34;w\u0026#34; options[\u0026#34;path\u0026#34;].open(mode=options[\u0026#34;mode\u0026#34;]).write_text(json.dumps(data)) This function writes a json file, but it also modifies the options dictionary. In Python, objects are passed by reference, which means:\noptions = {} write([1.0, 2.0], options=options) print(options) # {\u0026#34;mode\u0026#34;: \u0026#34;w\u0026#34;} This function has a side-effect on one of its parameters which can\u0026rsquo;t be guessed by looking at its signature. We could either change the name to something that explains why the side-effect, or we can get rid of it altogether:\ndef write(data: Union[Dict, List], path: pathlib.Path) -\u0026gt; None: path.open(mode=\u0026#34;w\u0026#34;).write_text(json.dumps(data)) This is another example of how following good naming principles has the great side-effect of making us write better code.\nComments #  Good code with good names doesn\u0026rsquo;t need comments. When you have to add a comment to your code is because you failed to express that idea in the code itself. Of course, there are exceptions to this. For example, if you\u0026rsquo;re forced to do something weird or not natural because of an external issue, that\u0026rsquo;s a good place for a comment. Or to explain why you can\u0026rsquo;t do something. In general, a good use of comments is when, if you had to express that idea in the code itself, the result would be messier. This is a good example of a comment:\ntree = KDTree(leaf_size=40) for point in points: nearest_neighbor = tree.query(point, k=1) Abstract common tasks to reduce bugs #  When you write code that does the same thing over and over it\u0026rsquo;s time to abstract it. It\u0026rsquo;s good to re-use code and it decreases the chances for bugs. When you write the same thing over and over, at some point you will forget something. For example, consider this code:\nCHUNK_SIZE = 200 partial_results = [] for i, row in enumerate(data): partial_results.append(process_row(row)) if i \u0026gt; 0 and i % CHUNK_SIZE == 0: upload_results(partial_results) partial_results = [] Here we forgot to upload the latest results. If data has 437 records, we upload the first 400 and forget about the last 37. This kind of task is general enough that it should be abstracted (this one is already in the std library but that\u0026rsquo;s not the point), because by the fifth you re-implement you will make mistakes.\nBoring is good #  This is bad:\ndata = [ line.strip().split(\u0026#34;\\t\u0026#34;) for line in open(\u0026#34;my_file.tab\u0026#34;) if not line.startswith(\u0026#34;#\u0026#34;) ]  Too much going on in a single line. The cognitive load is higher when so much stuff is happening at once. Is the file even closed at the end? (It is, but it\u0026rsquo;s not obvious, you need to know some internals of Python). If I want to do additional processing on the line, where do I put that code?  This is good:\ndata = [] with open(\u0026#34;my_file.tab\u0026#34;) as file: for line in file: if line.startswith(\u0026#34;#\u0026#34;): continue line = line.strip() data.append(line.split(\u0026#34;\\t\u0026#34;))  Less cognitive load, easier to read. Even if I don\u0026rsquo;t know anything about Python, it\u0026rsquo;s easy to guess that the file will be closed after it\u0026rsquo;s done. It\u0026rsquo;s easy to add additional code.  Testing as documentation #  TODO.\nTest as protection against future changes #  TODO.\nHow can this go wrong? #  TODO.\n"},{"id":9,"href":"/docs/topics/software-engineering/python/","title":"Python","section":"Software Engineering","content":"Python #  bar.\n"}]