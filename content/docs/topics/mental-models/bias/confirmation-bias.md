# Confirmation bias

## Introduction

[Confirmation bias](https://en.wikipedia.org/wiki/Confirmation_bias) is a mental model in which we cherry-pick evidence that confirms our beliefs while rejecting or ignoring anything that goes against them. This tendence is stronger in case of ideologically or emotionally charged arguments.

When we *want* a certain idea to be true, and we end up thinking and acting as if it was true, that is confirmation bias in action. Our eyes and brains filter out any information that would disprove what we have already decided to be true beyond doubt. On the contrary, we thoroughly embrace any bit of data that confirms our views, no matter how insignificant.

We basically stop perceiving the evidence objectively and start cherry-picking all those bits that strenghten our prior theories.

> *"What the human being is best at doing is interpreting all new information so that their prior conclusions remain intact."*
>
> -- Warren Buffett

## Examples

* When it comes to social and political issues, people are [entrenched in their existing beliefs and unwilling to change them](https://link.springer.com/article/10.1007/s11109-019-09526-z), no matter how convincing the conflicting evidence can be. Even worse, after considering and rejecting the evidence, people tend to become even more confident in the superiority of their positions.
* Socially anxious people have a marked tendency to interpret others' behaviours as confirming their beliefs that they're being judged, that people don't like them and so on. Any signal that suggests something negative is given paramount important, while positive signals are disregarded altogether.
* A consequence of confirmation bias is making self-fulfilling prophecies happen. For example, if you think you will suck at tomorrow's work presentation, you might end up having a sleepless night - which in turns increases the chance of you actually sucking at the presenation.

## History

Confirmation bias was first identified by the ancient Greeks. In [The History of the Peloponnesian War](https://en.wikipedia.org/wiki/History_of_the_Peloponnesian_War), Thucydides (c. 460 BC - c. 395 BC) said:

> *"For it is a habit of humanity to entrust to careless hope what they long for, and to use sovereign reason to thrust aside what they do not fancy."*

The Italian poet Dante Alighieri (1265-1321) noted in the [Divine Comedy](https://en.wikipedia.org/wiki/Divine_Comedy):

> *"Opinion--hasty--often can incline to the wrong side, and then affection for one's own opinion binds, confines the mind."*

In his [Muqaddimah](https://en.wikipedia.org/wiki/Muqaddimah) (1377), the Arab historian Ibn Khaldun says:

> *"Untruth naturally afflicts historical information. There are various reasons that make this unavoidable. One of them is partisanship for opinions and schools. \[...\] If the soul is infected with partisanship for a particular opinion or sect, it accepts without a moment's hesitation the information that is agreeable to it. Prejudice and partisanship obscure the critical faculty and preclude critical investigation. The result is that falsehoods are accepted and transmitted."*

In his [Novum Organum](https://en.wikipedia.org/wiki/Novum_Organum), English philosopher and scientist Francis Bacon (1561-1626) says:

> *"The human understanding when it has once adopted an opinion ... draws all things else to support and agree with it. And though there be a greater number and weight of instances to be found on the other side, yet these it either neglects or despises, or else by some distinction sets aside or rejects."*

In the second volume of [The World as Will and Representation](https://en.wikipedia.org/wiki/The_World_as_Will_and_Representation), German philosopher Arthur Schopenhauer says:

> *"An adopted hypothesis gives us lynx-eyes for everything that confirms it and makes us blind to everything that contradicts it."*

In his essay [What is Art?](https://en.wikipedia.org/wiki/What_Is_Art%3F) (1897) Leo Tolstoy wrote:

> *"I know that most men--not only those considered clever, but even those who are very clever, and capable of understanding most difficult scientific, mathematical, or philosophic problems--can very seldom discern even the simplest and most obvious truth if it be such as to oblige them to admit the falsity of conclusions they have formed, perhaps with much difficulty--conclusions of which they are proud, which they have taught to others, and on which they have built their lives."*

He also says in his essay [The Kingdom of God Is Within You](https://en.wikipedia.org/wiki/The_Kingdom_of_God_Is_Within_You) (1894):

> *"The most difficult subjects can be explained to the most slow-witted man if he has not formed any idea of them already; but the simplest thing cannot be made clear to the most intelligent man if he is firmly persuaded that he knows already, without a shadow of doubt, what is laid before him."*

## Confirmation bias and the brain

From an evolutionary perspective, having this bias makes sense, because it makes us save energy. Carefully and objectively analysing data requires a ton of effort. It is the reason why our brains like shortcuts. Also, in ancient times we didn't really have the luxury of sitting down, carefully weighting all the evidence, make pros and cons lists, and so on. In those times, the vast majority of decisions were about survival. Fight or flight and all that. The modern world brought with it incredible complexity, which our brains are definitely not equipped to handle. Today, we have to make multiple complex decisions every single day. No wonder we're always looking for shortcuts, our brains would explode otherwise.

Also, your brain spent countless hours creating and refining its mental model of how the world works. Evidence that challeges this model is hard to accept, because it would invalidate all the effort spent in building the model and because it's a threat to our sense of identity that's been created around this model of the world.

## Confirmation bias, conspiracy theories and social media

Confirmation bias is behind a lot of conspiracy theories, where people only look at those bits of evidence supporting their theories while rejecting everything else.

It is also used by social media companies like Facebook in their news feed. The algorithm behind the news feed shows you content you are likely to agree with, thereby feeding your already existing confirmation biases.

## What to do about it

Confirmation bias prevents us from realizing we were wrong, thus blocking the progress of our knowledge and of our journey towards becoming better decision makers. What we can do about it:

* Acknowledge that the world is an incredibly complicated thing to deal with, and that no matter how confident you are in your opinions, new evidence that throws your hypotheses in the gargabe could arrive any moment.
* Use the scientific method. Instead of thinking "How can I prove this is true?", think "How can I prove this is bullshit?". If despite your effort you cannot find convincing evidence your idea is bullshit, that is a pretty good argument in favor of it.
